{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-petersburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mpld3\n",
    "#mpld3.enable_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "different-foundation",
   "metadata": {},
   "source": [
    "## Comparison of new GC method for fragmented memory\n",
    "Read in data from results.txt file.  \n",
    "Has a description, 'Old Verion:', old data, 'New Version:', new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-percentage",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../wasm-of-ocaml/benchmarks/gc/results.txt\") as f:\n",
    "    old_data = []\n",
    "    new_data = []\n",
    "    new_with_threshold = []\n",
    "    version = 0\n",
    "    for line in f.readlines():\n",
    "        if line.strip() == \"\":\n",
    "            version += 1\n",
    "        if line[0].isdigit():\n",
    "            iters, mean, std = line.strip().split()\n",
    "            if version == 0:\n",
    "                old_data.append((int(iters), float(mean), float(std)))\n",
    "            elif version == 1:\n",
    "                new_data.append((int(iters), float(mean), float(std)))\n",
    "            else:\n",
    "                new_with_threshold.append((int(iters), float(mean), float(std)))\n",
    "\n",
    "# reaches limiting behaviour after about 1000 iterations, so truncate data\n",
    "#old_data = old_data[:-7]\n",
    "#new_data = new_data[:-7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-reducing",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(old_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-finger",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = [x[0] for x in old_data]\n",
    "y1 = np.array([x[1] for x in old_data])\n",
    "y1err = np.array([x[2] for x in old_data])\n",
    "y2 = np.array([x[1] for x in new_data])\n",
    "y2err = np.array([x[2] for x in new_data])\n",
    "y3 = np.array([x[1] for x in new_with_threshold])\n",
    "y3err = np.array([x[2] for x in new_with_threshold])\n",
    "\n",
    "# error bars are 1 std deviation\n",
    "# Now that all tracing information left out, much closer performance\n",
    "l1 = plt.errorbar(x, y1, yerr=y1err, label=\"old\")\n",
    "l2 = plt.errorbar(x, y2, yerr=y2err, label=\"new\")\n",
    "l3 = plt.errorbar(x, y3, yerr=y3err, label=\"new+threshold\")\n",
    "#plt.yscale(\"log\")\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.title(\"speedup\")\n",
    "plt.plot([],[])\n",
    "plt.plot(x, y1/y2)\n",
    "plt.plot(x, y1/y3)\n",
    "#plt.ylim(0, 5)\n",
    "#plt.ylim(1,np.max(y1/y2)*1.1)\n",
    "#plt.legend([l1, l2, l3], [\"old\", \"new\", \"new+threshold\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mechanical-animal",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(x))\n",
    "print(np.array(y1))\n",
    "print(np.array(y2))\n",
    "print(np.array(y3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-steering",
   "metadata": {},
   "source": [
    "## As above but for mergesort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functioning-youth",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../wasm-of-ocaml/benchmarks/gc/mergesort_results.txt\") as f:\n",
    "    old_data = []\n",
    "    new_data = []\n",
    "    new_with_threshold = []\n",
    "    version = 0\n",
    "    for line in f.readlines():\n",
    "        if line.strip() == \"\":\n",
    "            version += 1\n",
    "        if line[0].isdigit():\n",
    "            iters, mean, std = line.strip().split()\n",
    "            if version == 0:\n",
    "                old_data.append((int(iters), float(mean), float(std)))\n",
    "            elif version == 1:\n",
    "                new_data.append((int(iters), float(mean), float(std)))\n",
    "            else:\n",
    "                new_with_threshold.append((int(iters), float(mean), float(std)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wound-chapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_with_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gross-pharmaceutical",
   "metadata": {},
   "source": [
    "## Benefit of cutoff for repeating GC\n",
    "alltrees run with size 5, 6, 7, 8 and 9 (shadow stack overflow if tried with 10). Shows that old version and new version without threshold are near identical, but adding that threshold can dramatically reduce execution time. Execution time and memory usage of problem grows exponentially with tree size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-debate",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../wasm-of-ocaml/benchmarks/gc/alltrees_results.txt\") as f:\n",
    "    old_data1 = []\n",
    "    new_data1 = []\n",
    "    new_with_threshold_data = [] # always grow heap if only 1KB (256 words) could be freed\n",
    "    i = 0\n",
    "    for line in f.readlines():\n",
    "        if len(line.strip()) == 0:\n",
    "            i += 1\n",
    "        if line[0].isdigit():\n",
    "            iters, mean, std = line.strip().split()\n",
    "            if i == 0:\n",
    "                old_data1.append((int(iters), float(mean), float(std)))\n",
    "            elif i == 1:\n",
    "                new_data1.append((int(iters), float(mean), float(std)))\n",
    "            else:\n",
    "                new_with_threshold_data.append((int(iters), float(mean), float(std)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-ultimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [x[0] for x in old_data1]\n",
    "y1 = np.array([x[1] for x in old_data1])\n",
    "y1err = np.array([x[2] for x in old_data1])\n",
    "y2 = np.array([x[1] for x in new_data1])\n",
    "y2err = np.array([x[2] for x in new_data1])\n",
    "y3 = np.array([x[1] for x in new_with_threshold_data])\n",
    "y3err = np.array([x[2] for x in new_with_threshold_data])\n",
    "\n",
    "# error bars are 1 std deviation\n",
    "# Now that all tracing information left out, much closer performance\n",
    "plt.errorbar(x, y1, yerr=y1err, label=\"Old\")\n",
    "plt.errorbar(x, y2, yerr=y2err, label=\"New\")\n",
    "plt.errorbar(x, y3, yerr=y3err, label=\"New + Threshold\")\n",
    "sizes = np.array(x)\n",
    "plt.legend()\n",
    "plt.xticks(x)\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"speedup\")\n",
    "plt.plot(x, y1/y2, label=\"New\", c=\"tab:orange\")\n",
    "plt.plot(x, y1/y3, label=\"New + Threshold\", c=\"g\")\n",
    "plt.xticks(x)\n",
    "# mpld3 doesn't seem to work with hlines properly\n",
    "#plt.hlines(1.0, 5, 9, color='b', linestyle='dotted')\n",
    "plt.plot([5,10], [1,1], \"--\", label=\"Old\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parallel-attack",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)\n",
    "print(y1/y2)\n",
    "print(y1/y3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sitting-lender",
   "metadata": {},
   "source": [
    "Tracing data from alltrees 9, showing number of frees each time GC is called. Note the length of the x-axis i.e. the total number of GC calls made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-fishing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frees = []\n",
    "memgrows = []\n",
    "with open(\"../../wasm-of-ocaml/benchmarks/gc/trees9.txt\") as f:\n",
    "    f.readline()\n",
    "    frees = eval(f.readline())[:-1]\n",
    "    memgrows = eval(f.readline())[:-1]\n",
    "    \n",
    "#plt.figure(1,(0.03*len(frees),3))\n",
    "plt.figure(1,(12,3))\n",
    "\n",
    "plt.plot(frees, label=\"frees\")\n",
    "plt.vlines(np.where(memgrows), -300, -50, colors='k')\n",
    "# don't show the large free of 2x as many objects at the end of each trace\n",
    "plt.ylim(-200, 2200)\n",
    "plt.title(\"Without threshold\")\n",
    "\n",
    "frees = []\n",
    "memgrows = []\n",
    "with open(\"../../wasm-of-ocaml/benchmarks/gc/newTrees9.txt\") as f:\n",
    "    f.readline()\n",
    "    frees = eval(f.readline())[:-1]\n",
    "    memgrows = eval(f.readline())[:-1]\n",
    "\n",
    "# mark number of GC calls in optimised approach on the first plot\n",
    "n = len(frees)\n",
    "plt.plot([n,n],[-300,2200], \"g--\")\n",
    "    \n",
    "#plt.figure(2,(0.03*len(frees),3))\n",
    "plt.figure(2,(12,3))\n",
    "\n",
    "plt.plot(frees, \"g\", label=\"frees\")\n",
    "plt.vlines(np.where(memgrows), -300, -50, colors='k')\n",
    "plt.ylim(-200, 2200)\n",
    "plt.title(\"With threshold\");\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-discrimination",
   "metadata": {},
   "source": [
    "## More general results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lined-interpretation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(means, errors, baseline, keep=False):\n",
    "    new_means = {}\n",
    "    new_errors = {}\n",
    "    num_tests = len(means[baseline])\n",
    "    for version in means:\n",
    "        if version == baseline and not keep:\n",
    "            continue\n",
    "        new_means[version] = [means[version][i]/means[baseline][i] for i in range(num_tests)]\n",
    "        if errors is not None:\n",
    "            new_errors[version] =[errors[version][i]/means[baseline][i] for i in range(num_tests)]\n",
    "    return new_means, new_errors\n",
    "\n",
    "def bar_plot(ax, data, errors=None, colors=None, total_width=0.8, single_width=1, legend=False, capsize=3):\n",
    "    \"\"\"Draws a bar plot with multiple bars per data point.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ax : matplotlib.pyplot.axis\n",
    "        The axis we want to draw our plot on.\n",
    "\n",
    "    data: dictionary\n",
    "        A dictionary containing the data we want to plot. Keys are the names of the\n",
    "        data, the items is a list of the values.\n",
    "\n",
    "        Example:\n",
    "        data = {\n",
    "            \"x\":[1,2,3],\n",
    "            \"y\":[1,2,3],\n",
    "            \"z\":[1,2,3],\n",
    "        }\n",
    "\n",
    "    errors: dictionary, optional\n",
    "        Dictionary of standard deviations, corresponding structure to data\n",
    "\n",
    "    colors : array-like, optional\n",
    "        A list of colors which are used for the bars. If None, the colors\n",
    "        will be the standard matplotlib color cyle. (default: None)\n",
    "\n",
    "    total_width : float, optional, default: 0.8\n",
    "        The width of a bar group. 0.8 means that 80% of the x-axis is covered\n",
    "        by bars and 20% will be spaces between the bars.\n",
    "\n",
    "    single_width: float, optional, default: 1\n",
    "        The relative width of a single bar within a group. 1 means the bars\n",
    "        will touch eachother within a group, values less than 1 will make\n",
    "        these bars thinner.\n",
    "\n",
    "    legend: bool, optional, default: True\n",
    "        If this is set to true, a legend will be added to the axis.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if colors where provided, otherwhise use the default color cycle\n",
    "    if colors is None:\n",
    "        colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "    # Number of bars per group\n",
    "    n_bars = len(data)\n",
    "\n",
    "    # The width of a single bar\n",
    "    bar_width = total_width / n_bars\n",
    "\n",
    "    # List containing handles for the drawn bars, used for the legend\n",
    "    bars = []\n",
    "\n",
    "    # Iterate over all data\n",
    "    for i, (name, values) in enumerate(data.items()):\n",
    "        # The offset in x direction of that bar\n",
    "        x_offset = (i - n_bars / 2) * bar_width + bar_width / 2\n",
    "\n",
    "        # Draw a bar for every value of that type\n",
    "        for x, y in enumerate(values):\n",
    "            if errors is None:\n",
    "                bar = ax.bar(x + x_offset, y, width=bar_width * single_width, color=colors[i % len(colors)])\n",
    "            else:\n",
    "                err = errors[name][x]\n",
    "                bar = ax.bar(x + x_offset, y, yerr=err, error_kw=dict(capsize=capsize),\n",
    "                             width=bar_width * single_width, color=colors[i % len(colors)])\n",
    "\n",
    "        # Add a handle to the last drawn bar, which we'll need for the legend\n",
    "        bars.append(bar[0])\n",
    "\n",
    "#    # Draw legend if we need\n",
    "#    if legend:\n",
    "#        ax.legend(bars, data.keys())\n",
    "    # return the handlers/labels for a legend\n",
    "    if legend:\n",
    "        return bars, data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-newspaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "labels = [\"New+Threshold\", \"None\", \"New\", \"Old\"]\n",
    "# Check file to see formatting\n",
    "with open(\"../../wasm-of-ocaml/benchmarks/evaluation/ocaml_results.txt\") as f:\n",
    "    f.readline()\n",
    "    for i in labels:\n",
    "        f.readline()\n",
    "        line = f.readline().strip().split()\n",
    "        while line != []:\n",
    "            if line[0] not in data:\n",
    "                data[line[0]] = {}\n",
    "            data[line[0]][i] = \\\n",
    "              {\"time\" : float(line[1]), \"error\" : float(line[2]), \"heap\": float(line[3]), \"filesize\" : float(line[4])}\n",
    "            line = f.readline().strip().split()\n",
    "tests = data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollow-survival",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(12,10))\n",
    "labels = [\"Old\", \"New\", \"New+Threshold\"]\n",
    "ax = axs[0]\n",
    "times = {i: [data[test][i][\"time\"] for test in tests] for i in labels}\n",
    "errors = {i: [data[test][i][\"error\"] for test in tests] for i in labels}\n",
    "times, errors = normalise(times, errors, \"Old\", True)\n",
    "#times = {lang : [means[lang][b] for b in benchmarks if b != \"arith\"] for lang in means if lang != \"Grain\"}\n",
    "bar_plot(ax, times, errors=errors)\n",
    "ax.set_title(\"Execution time\")\n",
    "ax.set_xticks([])\n",
    "ax.set_ylabel(\"relative time\")\n",
    "\n",
    "ax = axs[1]\n",
    "mem = {i: [data[test][i][\"heap\"] for test in tests] for i in labels}\n",
    "mem, _ = normalise(mem, None, \"Old\", True)\n",
    "handlers, labels = bar_plot(ax, mem, legend=True)\n",
    "ax.set_title(\"Heap usage\")\n",
    "ax.set_xticks([])\n",
    "#ax.set_yscale(\"log\")\n",
    "ax.set_ylabel(\"Memory (bytes)\")\n",
    "\n",
    "fig.legend(handlers, labels, loc='center left');\n",
    "plt.subplots_adjust(left=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-slovenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "periodic-dimension",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"Old\", \"New\", \"New+Threshold\"]\n",
    "cases = [0, 3, 5, 6, 7, 9]\n",
    "#print([list(tests)[i] for i in cases])\n",
    "print(\"times = [\" +  \"; \".join([\" \".join([str(times[label][i]) for label in labels]) for i in range(len(tests))]) + \"];\")\n",
    "print(\"errors = [\" +  \"; \".join([\" \".join([str(errors[label][i]) for label in labels]) for i in range(len(tests))]) + \"];\")\n",
    "print()\n",
    "print(\"mems = [\" +  \"; \".join([\" \".join([str(mem[label][i]) for label in labels]) for i in range(len(tests))]) + \"];\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
